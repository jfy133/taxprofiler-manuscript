[
  {
    "objectID": "taxprofiler-manuscript.html",
    "href": "taxprofiler-manuscript.html",
    "title": "nf-core/taxprofiler: highly parallelised and flexible pipeline for metagenomic taxonomic classification and profiling",
    "section": "",
    "text": "Metagenomic classification tackles the problem of characterising the taxonomic source of all DNA sequencing reads in a sample. A common approach to address the differences and biases between the many different taxonomic classification tools is to run metagenomic data through multiple classification tools and databases. This, however, is a very time-consuming task when performed manually - particularly when combined with the appropriate preprocessing of sequencing reads before the classification.\nHere we present nf-core/taxprofiler, a highly parallelised taxonomic classification and processing pipeline that allows for automated and simultaneous classification and/or profiling of both short- and long-read metagenomic sequencing libraries against a large number of taxonomic classifiers and profilers as well as databases within a single pipeline run. Implemented in Nextflow and as part of the nf-core initiative, the pipeline benefits from high levels of scalability and portability, accommodating from small to extremely large projects on a wide range of computing infrastructure. It has been developed following best-practise software development practises and community support to ensure longevity and adaptability of the pipeline, to help keep it up to date with the field of metagenomics."
  },
  {
    "objectID": "taxprofiler-manuscript.html#abstract",
    "href": "taxprofiler-manuscript.html#abstract",
    "title": "nf-core/taxprofiler: highly parallelised and flexible pipeline for metagenomic taxonomic classification and profiling",
    "section": "",
    "text": "Metagenomic classification tackles the problem of characterising the taxonomic source of all DNA sequencing reads in a sample. A common approach to address the differences and biases between the many different taxonomic classification tools is to run metagenomic data through multiple classification tools and databases. This, however, is a very time-consuming task when performed manually - particularly when combined with the appropriate preprocessing of sequencing reads before the classification.\nHere we present nf-core/taxprofiler, a highly parallelised taxonomic classification and processing pipeline that allows for automated and simultaneous classification and/or profiling of both short- and long-read metagenomic sequencing libraries against a large number of taxonomic classifiers and profilers as well as databases within a single pipeline run. Implemented in Nextflow and as part of the nf-core initiative, the pipeline benefits from high levels of scalability and portability, accommodating from small to extremely large projects on a wide range of computing infrastructure. It has been developed following best-practise software development practises and community support to ensure longevity and adaptability of the pipeline, to help keep it up to date with the field of metagenomics."
  },
  {
    "objectID": "taxprofiler-manuscript.html#introduction",
    "href": "taxprofiler-manuscript.html#introduction",
    "title": "nf-core/taxprofiler: highly parallelised and flexible pipeline for metagenomic taxonomic classification and profiling",
    "section": "2 Introduction",
    "text": "2 Introduction\nWhole-genome, metagenomic sequencing offers strong benefits to the taxonomic classification of DNA samples over targeted approaches (Eloe-Fadrosh et al. 2016; Florian P. Breitwieser, Lu, and Salzberg 2019). While metabarcoding approaches targeting the 16S rRNA or other marker genes are widely used due to low cost and large, diverse reference databases (Yilmaz et al. 2014; Lynch and Neufeld 2015), metagenomic approaches have been gaining popularity with the increasingly lower costs of, for example, shotgun sequencing. These metagenomic analyses have been shown to provide a similar resolution on microbial genomes during taxonomic classification (Hillmann et al. 2018), with the added benefit of having greater reusability potential of the data, via whole genome reconstruction and also functional classification of metagenomics (Sharpton 2014; Quince et al. 2017).\nTaxonomic classifiers (sometimes referred to as taxonomic binners) aim to identify the original ‘taxonomic source’ of a given DNA sequence (Ye et al. 2019; Meyer et al. 2022; Govender and Eyre 2022). In metagenomics, this typically consists of comparing millions of DNA reads (sequenced DNA molecules) against hundreds or thousands of reference genomes either via sequence alignment or ‘k-mer matching’ (Sharpton 2014; Sun et al. 2021), with the most close match being considered the most likely original ‘source’ organism of that sequence. We will also refer to taxonomic profilers that are classifiers that also try to infer species abundance of the organism in the original sample, in addition to the typical sequence abundance (Nayfach and Pollard 2016). We will use classifiers and profilers interchangeably throughout the publication.\nDue to the scale of the problem, taxonomic profiling remains an ‘unresolved problem’ in bioinformatics.  Having to identify the original source of many sequences out of many reference genomes, but in an efficient manner, is understandably a difficult problem. Therefore a plethora of tools have been developed to address this challenge, all with their own biases and specific contexts (Sczyrba et al. 2017; Meyer et al. 2022). Additionally, each tool often produces tool-specific output formats making it difficult to efficiently cross compare results. Thus, no established ‘gold standard’ classifier tool or method currently exists.\nOne solution to addressing the problem of choice among the range of different tools is to run all of them in parallel, and cross compare the results. This can be useful both for benchmarking studies (e.g. Sczyrba et al. 2017; Meyer et al. 2022), but also to build consensus profiles whereby confidence of a particular taxonomic identification can be increased when it is detected by multiple tools (McIntyre et al. 2017; Ye et al. 2019).\nA second challenge in taxonomic classification (and arguably a larger one) is a question of databases. As with tools, there is no one set ‘gold standard’ database. Different questions and contexts require different databases, such as when a researcher wants to search for both bacterial and viral species in samples, and as an extension of this, taxonomic classifiers may need different settings for each database. Furthermore, as genomic sequencing becomes cheaper and more efficient, the number of publicly available reference genomes is rapidly increasing (Nasko et al. 2018). Consequently, the size of reference databases of taxonomic classifiers is also growing, often outpacing the computational capacity available to researchers. In fact, while this was one of the main motivations behind classifiers such as Kraken2 (Wood, Lu, and Langmead 2019), these algorithmic techniques are already becoming insufficient (Wright, Comeau, and Langille 2023).\nFinally, with the decrease of costs, the possibility for larger and larger metagenomic sequencing datasets increases, leading to increasing sample sizes in studies. This is exemplified by the doubling of the number of metagenomes on the European Bioinformatic Institute’s MGnify database within just two years (Mitchell et al. 2019).\nAltogether this highlights the need for methods to efficiently profile many samples using many tools. Manually setting up bioinformatic jobs for classification tasks for each database and settings against different tools on traditional academic computing infrastructure (e.g. high performance computing clusters or ‘HPC’ clusters) can be very tedious. Additionally, particularly for very large sample sets, there is increasing use of cloud platforms that have greater scalability than traditional HPCs. Being able to reliably and reproducibly execute taxonomic classification tasks across infrastructure with minimal intervention would therefore be a boon for the metagenomics field.\nIn reason years, workflow managers such as Nextflow (Di Tommaso et al. 2017) or Snakemake (Mölder et al. 2021) have become highly popular in bioinformatics. These frameworks provide for developers robust workflow execution with different HPC scheduling tools and software provisioning systems, ensuring maximum portability and efficient in different computational contexts. While a range of metagenomic pipelines already exist (a non-exhaustive list being for example, Boulund et al. 2023; Piro, Matschkowski, and Renard 2017; Sim et al. 2020; Rose et al. 2019; Clarke et al. 2019), few leverage workflow managers to make multi-step workflows easier to use in HPC or cloud infrastructure. Furthermore, often these pipelines aim to carry out multiple different types of metagenomic analyses Boulund et al. (2023) of which each step has fewer options of tools and may be unwanted by the end user.\nHere we present nf-core/taxprofiler, a pipeline designed to allow users to efficiently and simultaneously taxonomically classify and profile short- and long-read sequencing data against (at the time of writing 11 classifiers and databases in a single pipeline run. nf-core/taxprofiler utilises Nextflow (Di Tommaso et al. 2017) to ensure efficiency, portability, and scalability, and has been developed within the nf-core initiative of Nextflow pipelines (Ewels et al. 2020) to ensure high quality coding practises and user accessibility, including detailed documentation and a graphical-user-interface (GUI) execution interface."
  },
  {
    "objectID": "taxprofiler-manuscript.html#description",
    "href": "taxprofiler-manuscript.html#description",
    "title": "nf-core/taxprofiler: highly parallelised and flexible pipeline for metagenomic taxonomic classification and profiling",
    "section": "3 Description",
    "text": "3 Description\nnf-core/taxprofiler aims to facilitate three main steps of a typical whole-genome, metagenomic sequencing analysis workflow (Chiu and Miller 2019, Figure 1). A longer description of the available functionality and motivations can be seen in the Supplementary Information.\nIn brief, nf-core/taxprofiler can accept short- (e.g. Illumina) and/or long-read (e.g. Nanopore) FASTQ or FASTA files. These are supplied to the pipeline in the form of a TSV file that includes basic sample and sequencing library metadata. The pipeline can then be executed either via a standard Nextflow command-line-interface (CLI) execution or graphical-user-interface (GUI) through either the open-source and free nf-core launch page (https://nf-core/launch) or the commercial (with free-tier) Nextflow tower (https://tower.nf) solution. Examples of the command-line execution and nf-core launch GUI can be seen in the Supplementary Information.\nTHe pipeline can perform a range of metagenomics appropriate read preprocessing steps, such adapter removal, read merging, low-sequence complexity filtering, host- or contamination removal, and/or per-sample run merging. All of these steps are optional, and are aimed at removing possible sequencing artefacts that may result in false positive taxonomic classification hits or improve classification efficiency. Most of these steps also provide options of different tools to allow user preference.\nAfter pre-processing, nf-core/taxprofiler can perform simultaneous profiling of preprocessing reads as many as 11 different taxonomic classifiers or profilers (Table 1), and on top of this, simultaneous for each of these an arbitrary number of databases supplied by the user. As of version 1.1.0, the following classifiers and profilers are available: Kraken2 (Wood, Lu, and Langmead 2019), Bracken (Lu et al. 2017), KrakenUniq (F. P. Breitwieser, Baker, and Salzberg 2018), Centrifuge (Kim et al. 2016), MALT (Vågene et al. 2018), DIAMOND (Buchfink, Reuter, and Drost 2021), Kaiju (Menzel, Ng, and Krogh 2016), MetaPhlAn (Blanco-Míguez et al. 2023), mOTUs (Ruscheweyh et al. 2022), ganon (Piro et al. 2020), KMCP (Shen et al. 2023). Databases are also supplied via a input TSV file, that also allows per-database custom classification parameters - meaning a given database can be supplied multiple times each with different parameters. All classifiers with secondary steps to generate or convert to additional output file formats are also included.\nPost-processing of taxonomic profiles include standardisation and aggregation of profiles , i.e., merging of multiple profiles into a single multi-sample table, for easier comparison between profilers with the tool TAXPASTA (Beber et al. 2023), and visualisation of profiles with Krona (Ondov, Bergman, and Phillippy 2011) for supported classifiers.\nAll relevant preprocessing statistics are displayed in an interactive and dynamic MultiQC report (Ewels et al. 2020).\n\n\n\nFigure 1: Visual overview of the nf-core/taxprofiler workflow. nf-core/taxprofiler can take in FASTQ (short or long reads) or FASTA files (long reads), that will optionally go through sequencing quality control (e.g. with FastQC), read preprocessing (e.g. removal of adapters), complexity filtering, host removal, and run merging before performing taxonomic classification and/or profiling with a user-selected range of tools and databases. Output from all classifiers and profilers are standardised into a common taxon table format, and when supported visualisations of the profiles are generated.\n\n\n\n\nTable 1: List of nf-core/taxprofiler supported taxonomic/classifiers profilers as of version 1.1 and their approximate method and supported input database types. Sequencing matching type refers to which ‘molecular alphabet’ is primarily used for matching between a query (read) and a reference (genome/gene). Primary algorithm refers to the algorithm type used for sequencing matching. Reference type refers to the typical sequence type used in database construction of the tool. Method refers to whether the tool performs just read classification (classifier) or additionally abundance estimation (profiler)\n\n\n\n\n\n\n\n\n\nTool\nPrimary Algorithm\nReference Type\nMethod\nSequence Matching Type\n\n\n\n\nKraken2\nk-mer based\nwhole-genome\nclassifier\nNucleotide\n\n\nKaiju\nk-mer based\nwhole-genome\nclassifier\nAmino Acid\n\n\nBracken\nk-mer based\nwhole-genome\nprofiler\nNucleotide\n\n\nKrakenUniq\nk-mer based\nwhole-genome\nprofiler\nNucleotide\n\n\nganon\nk-mer based\nwhole-genome\nprofiler\nNucleotide\n\n\nKMCP\nk-mer based\nwhole-genome\nprofiler\nNucleotide\n\n\nMALT\nalignment based\nwhole-genome\nclassifier\nNucleotide/Amino Acid\n\n\nDIAMOND\nalignment based\nwhole-genome\nclassifier\nAmino Acid\n\n\nCentrifuge\nalignment based\nwhole-genome\nprofiler\nNucleotide\n\n\nMetaPhlAn\nalignment based\nmarker-gene\nprofiler\nNucleotide\n\n\nmOTUS\nalignment based\nmarker-gene\nprofiler\nNucleotide\n\n\n\n\nnf-core/taxprofiler comes with extensive documentation for general usage, short- and long- parameter help texts, and output file descriptions. To ensure maximum accessibility, these are available in pipeline results as markdown files, on the nf-core website and for the parameter help texts on the command line via standard --help. The output documentation also aims to guide users as the most suitable files for different types of downstream analysis"
  },
  {
    "objectID": "taxprofiler-manuscript.html#discussion",
    "href": "taxprofiler-manuscript.html#discussion",
    "title": "nf-core/taxprofiler: highly parallelised and flexible pipeline for metagenomic taxonomic classification and profiling",
    "section": "4 Discussion",
    "text": "4 Discussion\nA range of pipelines already exists for taxonomic profiling, however, each have their own particular purpose and capabilities. We compared the functionality of nf-core/taxprofiler against four other recently published or released pipelines, selected based on their similarity of purpose to nf-core/taxprofiler. The selection criteria and a more detailed comparison between the five pipelines can be seen in the Supplementary Information. Overall, while there was a general similarity across all pipelines, nf-core/taxprofiler showed the largest number of functionality for pipeline execution accessibility and user choice, through the use of an established workflow manager (with Nextflow supporting 7 software environment/container systems), supporting both CLI and GUI execution, and the number of supported classifiers. Furthermore, it is unique in that is the only pipeline to support supplying multiple database for all of the tools in a single pipeline run.\n\n\nTable 2: Comparison of functionality with four recent taxonomic pipelines with similar functionality. A more detailed textual comparison can be found in the Supplementary Information. Category keys are as follows: I - Information, R - Reproducibility, A - Accessibility, P - Portability, S - Scalability, F - Functionality.\n\n\nCategory\nCriterion\nStaG-mwc\nsunbeam\nUnipro UGENE\ntama\nnf-core/taxprofiler\n\n\n\n\nI\nSource code URL\nhttps://github.com/ctmrbio/stag-mwc\nhttps://github.com/sunbeam-labs/sunbeam\nhttps://github.com/ugeneunipro/ugene\nhttps://github.com/jkimlab/TAMA\nhttps://github.com/nf-core/taxprofiler/\n\n\nI\nEvaluated version\n0.7.0\n4\n48\ngithash: 3a22c8f\n1.1.0\n\n\nI\nLast release date\n2023-06-13\n2023-08-08\n2023-08-08\n2022-03-02\n2023-09-19\n\n\nI\nPublication year\nUnpublished\n2019\n2019\n2020\nThis publication\n\n\nI\nPublication DOI\nUnpublished\n10.1186/s40168-019-0658-x\n10.1093/bioinformatics/bty901\n10.1186/s12859-020-3533-7\nThis publication\n\n\nR\nPipeline versioning\nYes\nYes\nYes\nNo\nYes\n\n\nR\nSoftware versioning\nYes\nYes\nYes\nYes\nYes\n\n\nR\nNr. software environments or container engines supported\n2\n2\n0\n1\n7\n\n\nA\nInstallation documentation\nYes\nYes\nYes\nYes\nYes\n\n\nA\nUsage documentation\nYes\nYes\nYes\nYes\nYes\n\n\nA\nOutput documentation\nYes\nYes\nYes\nYes\nYes\n\n\nA\nCLI execution interface\nYes\nYes\nNo\nYes\nYes\n\n\nA\nGUI execution interface\nNo\nNo\nYes\nNo\nYes\n\n\nA/S\nIntegration a scheduling systems\nYes\nYes\nNo\nNo\nYes\n\n\nP/A\nNr. supported operating systems\n2\n1\n3\n1\n2\n\n\nP\nLocal machine integration\nYes\nYes\nYes\nYes\nYes\n\n\nP/S\nHPC scheduler integration\nYes\nYes\nNo\nNo\nYes\n\n\nP/S\nCloud computing integration\nUnsure\nUnsure\nNo\nNo\nYes\n\n\nP/S\nIntegration with multiple scheduling systems\nPartial\nPartial\nNo\nNo\nYes\n\n\nS\nPer-process resource optimisation\nYes\nYes\nYes\nNo\nYes\n\n\nF\nShort read support\nYes\nYes\nYes\nYes\nYes\n\n\nF\nLong read support\nNo\nNo\nYes\nNo\nYes\n\n\nF\nRead preprocessing\nYes\nYes\nYes\nYes\nYes\n\n\nF\nSequencing depth estimation\nYes\nNo\nNo\nNo\nNo\n\n\nF\nComplexity filtering\nNo\nYes\nNo\nNo\nYes\n\n\nF\nHost removal\nYes\nYes\nPartial\nNo\nYes\n\n\nF\nNr. supported taxonomic classifiers/profilers\n7\n3\n3\n3\n11\n\n\nF\nGraphical run reports\nYes\nNo\nNo\nNo\nYes\n\n\nF\nStandardised profiles\nNo\nNo\nNo\nYes\nYes\n\n\nF\nMultiple database supported\nPartial\nNo\nNo\nNo\nYes\n\n\nF\nMetagenomic assembly\nNo\nYes\nNo\nNo\nNo\n\n\nF\nVisualisation\nNo\nNo\nNo\nNo\nPartial\n\n\n\n\nAnother important advantage of nf-core/taxprofiler is that it is being developed within the nf-core community (https://nf-co.re), that provides strong long-term support for the continued community-based development and maintenance of its pipelines.\nIn this framework, we will continue to add additional preprocessing, metagenomic classification, and profiling tools as they become established and as requested by the metagenomics community, for example, we feel that the inclusion of steps such as sequencing saturation estimation as already being performed by a similar pipeline StaG-mwc (https://github.com/ctmrbio/stag-mwc) would be beneficial to the nf-core/taxprofiler workflow (possibly with dedicated tools such as Nonpareil, Rodriguez-R et al. 2018), and/or more performant complexity filtering tools such as Komplexity as offered by the sunbeam metagenomics pipeline (Clarke et al. 2019). Additional tools that could be added for short-read classification could include sourmash (Titus Brown and Irber 2016) that provides scalable sequence to sequence comparison or other marker gene reference tools such as tools such as METAXA2 (Bengtsson-Palme et al. 2015) that use shotgun sequencing reads to recover 16S sequences from metagenomic samples. Adding additional classifiers also applies to extend support to other sequencing platforms; nf-core/taxprofiler already supports Nanopore long-read data, however the use of long-read PacBio data for metagenomic data is growing in interest (Portik, Brown, and Pierce-Ward 2022). We are therefore considering adding dedicated preprocessing steps for this type of sequencing data.\nA remaining major challenge for metagenomics researchers (and not supported in the same workflow by any of the compared pipelines above) is the construction of databases for each profiling tool. Given there still are no curated, high-quality ‘gold standard’ databases in metagenomics, and while nf-core/taxprofiler allows the profiling against multiple databases and settings in parallel, currently the pipeline still requires users to construct these manually and to supply to the pipeline. While we feel this is currently a reasonable investment as such databases can be repeatedly re-used, we are exploring the possibility to add an additional complementary workflow in the pipeline to allow automated database construction of all classification tools, given a set of FASTA reference files.\nFinally, once an overall taxonomic profile is generated, researchers often wish to validate hits through more sensitive and accurate methods such as with read-mapping alignment. While read alignment is supported by other pipelines such as StaG-mwc, this happens in-parallel to the taxonomic profiling and requires prior expectation of which reference genomes to map against. Instead, nf-core/taxprofiler could be easily extended to have a validation step similar to the approach of the ancient DNA metagenomic pipeline aMeta (Pochon et al. 2022). Utilising Nextflow’s execution parallelism, the input sequences could be aligned back to the reference genomes of only those species with hits resulting from the taxonomic classification, but with dedicated accurate short- or long-read aligners. In addition to the more precise classification, post-classification read-alignment could also be particularly useful for researchers in palaeogenomics who wish to use tools other than KrakenUniq for initial classification (as in aMeta), where alignment information can be used to authenticate ancient DNA within their samples, but also in clinical metagenomics to identify potential pathogens at much finer resolution (e.g. down to strain level).\n\nAnother motivation for developing nf-core/taxprofiler, despite the large number of existing metagenomics pipelines, is that by establishing a taxonomic profiling pipeline within the nf-core ecosystem, it is possible to begin building both standalone but also an integrated suite of powerful interconnected pipelines for the major stages of metagenomic workflows. Existing microbial- and metagenomics- related pipelines within the nf-core initiative include nf-core/ampliseq (Straub et al. 2020), nf-core/mag (Krakau et al. 2022), and nf-core/funcscan (https://nf-co.re/funcscan). We expect over time the ability to link inputs and outputs of each workflow to develop comprehensive metagenomic analyses, while still maintaining powerful standalone pipelines, providing maximal user choice."
  },
  {
    "objectID": "taxprofiler-manuscript.html#conclusion",
    "href": "taxprofiler-manuscript.html#conclusion",
    "title": "nf-core/taxprofiler: highly parallelised and flexible pipeline for metagenomic taxonomic classification and profiling",
    "section": "5 Conclusion",
    "text": "5 Conclusion\nnf-core/taxprofiler is an accessible, efficient, and scalable pipeline for metagenomic taxonomic classification and profiling that can be executed on anywhere from laptops to the cloud. To our knowledge, the pipeline offers the largest number of taxonomic profilers across similar pipelines, providing flexibility for users not just on choice of profiling tool but also with databases and database settings, with any number being able to be supplied to the pipeline in a single run. With the development within the open and welcoming nf-core community and with best-practise development infrastructure, we look forward to further contributions and involvement of the wider metagenomics community, and also we hope that through detailed documentation and a range of execution options, nf-core/taxprofiler will make reproducible and high-throughput metagenomics more accessible for a wide range of disciplines."
  },
  {
    "objectID": "taxprofiler-manuscript.html#data-availability",
    "href": "taxprofiler-manuscript.html#data-availability",
    "title": "nf-core/taxprofiler: highly parallelised and flexible pipeline for metagenomic taxonomic classification and profiling",
    "section": "6 Data Availability",
    "text": "6 Data Availability\nAll data used in this publication"
  },
  {
    "objectID": "taxprofiler-manuscript.html#code-availability",
    "href": "taxprofiler-manuscript.html#code-availability",
    "title": "nf-core/taxprofiler: highly parallelised and flexible pipeline for metagenomic taxonomic classification and profiling",
    "section": "7 Code Availability",
    "text": "7 Code Availability\nnf-core/taxprofiler source code is available on GitHub at https://github.com/nf-core/taxprofiler, and each release is archived on Zenodo (latest version DOI: 10.5281/zenodo.7728364)\nThe version of the pipeline described in this paper is version (1.1.0) (release specific Zenodo archive DOI: 10.5281/zenodo.8358147)"
  },
  {
    "objectID": "taxprofiler-manuscript.html#supplementary-data",
    "href": "taxprofiler-manuscript.html#supplementary-data",
    "title": "nf-core/taxprofiler: highly parallelised and flexible pipeline for metagenomic taxonomic classification and profiling",
    "section": "8 Supplementary Data",
    "text": "8 Supplementary Data"
  },
  {
    "objectID": "taxprofiler-manuscript.html#acknowledgments",
    "href": "taxprofiler-manuscript.html#acknowledgments",
    "title": "nf-core/taxprofiler: highly parallelised and flexible pipeline for metagenomic taxonomic classification and profiling",
    "section": "9 Acknowledgments",
    "text": "9 Acknowledgments\nWe thank Prof. Christina Warinner and the Microbiome Sciences group MPI-EVA for original discussions that lead to the pipeline. We are also grateful for the nf-core community for the original and ongoing support in the development in the pipeline, in particular for the contributions by Lauri Mesilaakso, Jianhong Ou, and Rafał Stępień."
  },
  {
    "objectID": "taxprofiler-manuscript.html#funding",
    "href": "taxprofiler-manuscript.html#funding",
    "title": "nf-core/taxprofiler: highly parallelised and flexible pipeline for metagenomic taxonomic classification and profiling",
    "section": "10 Funding",
    "text": "10 Funding\nS.S. and L.A-L. were supported by Rapid establishment of comprehensive laboratory pandemic preparedness – RAPID-SEQ. This material is based upon work supported by the U.S. Department of Agriculture, Agricultural Research Service, under agreement No. 58-3022-0-001 (T.A.C II). M.B. and J.A.F.Y were supported by the Max Planck Society. J.A.F.Y was supported by the Werner Siemens-Stiftung (“Paleobiotechnology”, Awarded to Prof. Pierre Stallforth and Prof. Christina Warinner)."
  },
  {
    "objectID": "taxprofiler-manuscript.html#supplementary-information",
    "href": "taxprofiler-manuscript.html#supplementary-information",
    "title": "nf-core/taxprofiler: highly parallelised and flexible pipeline for metagenomic taxonomic classification and profiling",
    "section": "11 Supplementary Information",
    "text": "11 Supplementary Information\n\n11.1 Implementation\n\n11.1.1 Input and Execution\nThe pipeline can be executed via typical Nextflow commands, or using the standard nf-core ‘launch’ GUI (https://nf-co.re/taxprofiler/launch), making the pipeline accessible for both computationally experienced as well as less experienced researchers. In addition to the general usage and parameter documentation of the pipeline (https://nf-co.re/taxprofiler). The GUI offers immediate assistance and guidance to users on what each parameter does, both in short- and long-form, with long-form parameter descriptions additionally describing which tool-specific parameters are being modified for each pipeline parameter (Figure 2). The GUI also includes controlled user input by providing strict drop-down lists and input validation prior execution of the pipeline to reduce the risk of typos and other mistakes (in contrast to the command-line interface (CLI) that only includes validation at pipeline run-time).\n\n\n\nFigure 2: Screenshot of the nf-core pipeline launch graphical user interface with nf-core/taxprofiler options displayed. The web browser-based interface provides guidance for how to configure each pipeline parameter by providing both short and long help descriptions to help guide users in which contexts to configure each parameter. Additional elements such as radio buttons, drop down menus, and background regular expressions check for validity of input. When pressing launch, a prepared configuration file and command is provided that can be copied and pasted by the user into the terminal\n\n\nAn example nf-core command line execution of the pipeline can be seen in Code Block 1, where two input files are supplied: one file specifying paths of FASTQ files of metagenomic samples and necessary metadata for preprocessing (such as sample ID and sequencing platform), and the second file specifying paths to the user-defined databases with per-database classification parameters. Various parameters are available to select different preprocessing steps, and provide additional configuration such as tool selection and value options. Note that even if a user supplies a given database in the database input sheet, the corresponding profiling tool must still be activated with the corresponding pipeline parameter (e.g. --run_kraken2). Per-classifier flags are also available for the optional saving of additional non-profile output files. Alternatively to command line flags, parameters can be specified via pre-configured YAML format files, with which (provided no hardcoded paths are included) can be re-used across pipeline runs.\n\nListing 1: Example nf-core/taxprofiler command for running short-read quality control, removal of host DNA and executing the k-mer based Kraken2 and marker gene alignment MetaPhlAn3 tools.\n$ nextflow run nf-core/taxprofiler \\\n    -r 1.1.0 \\\n    -profile singularity,&lt;institute&gt; \\\n    --input &lt;samplesheet.csv&gt; \\\n    --databases &lt;database.csv&gt; \\\n    --perform_shortread_qc \\\n    --shortread_qc_minlength 20 \\\n    --preprocessing_qc_tool falco \\\n    --run_host_removal --hostremoval_reference 'host_genome.fasta' \\\n    --run_kraken2 --kraken2_save_reads \\\n    --run_metaphlan3 \\\n    --run_krona \\\n    --run_profile_standardisation\n\nAll nf-core pipelines are strictly versioned (specified with the Nextflow -r flag), and to ensure reproducibility, each version of the pipeline has a fixed set of software used for each step of the pipeline. The fixed set of software are controlled through the use of the conda package manager or containers (e.g., Docker, or Apptainer -previously known as Singularity) from the stable Bioconda (Grüning et al. 2018) or BioContainers (Veiga Leprevost et al. 2017) repositories. This, coupled with the intrinsic Nextflow ability to execute on most infrastructure whether that is a local laptop (resource requirements permitting), traditional HPC, as well across common cloud providers also makes nf-core/taxprofiler a very portable pipeline that can be used in many contexts.\n\n\n11.1.2 Preprocessing\nPreprocessing steps in nf-core/taxprofiler are aimed at removing laboratory and sequencing artefacts that may influence taxonomic profiling, either for computing resource consumption or and/or false-positive or false-negative classification reasons. First sequencing quality control with FastQC (Andrews 2010) or Falco (Sena Brandine and Smith 2021) is carried out. Falco was included for reduced memory requirements, in particular for long read sequencing data. Artificial library adapter sequences added during sequencing reduce sequencing matching accuracy by reducing sequence specificity, and in some cases, may result in false-positive hits due to adapter sequence contamination in reference genomes (Schäffer et al. 2018; F. P. Breitwieser, Baker, and Salzberg 2018) 1. Additionally, paired-end merging may provide longer sequences that will allow for more specific classification when paired-end alignment is not supported by a given classifier. For these tasks nf-core/taxprofiler can apply either fastp (Chen et al. 2018) or AdapterRemoval2 (Schubert, Lindgreen, and Orlando 2016) for short reads, and currently Porechop (Wick et al. 2017) for Oxford Nanopore long-read data. For both short and long reads, FastQC or Falco is run again to allow assessment on the performance of the adapter removal and/or pair-merging step.\nLow complexity sequences, e.g. sequences containing long stretches of mono- or di-nucleotide repeats provide little specific genetic information that contribute to taxonomic identification, as they can align to many different reference genomes (Schmieder and Edwards 2011; Clarke et al. 2019). Including such reads during taxonomic profiling can increase run-time and memory usage for little gain, as during lowest-common-ancestor (LCA) classification steps they will be assigned to high-level taxonomic ranks (e.g. Kingdom). nf-core/taxprofiler performs removal of these reads through complexity filtering algorithms as provided by fastp, BBDuk (Bushnell 2022), or PRINSEQ++ (Cantu, Sadural, and Edwards 2019). Long read sequences often do not have such reads, as lengths are sufficient enough to capture greater sequence diversity - but it is sometimes desirable to only classify reads longer than a certain length - as these provide more precise taxonomic information (Dilthey et al. 2019; Portik, Brown, and Pierce-Ward 2022). Therefore, nf-core/taxprofiler can remove reads shorter than a user-defined length using Filtlong.\nRemoving host DNA is another common preprocessing step in metagenomic studies. This can help speed up run-time, particularly in microbiome studies, where detection of microbes are of interest. Furthermore, host-contamination of reference genomes in public databases is common (Longo, O’Neill, and O’Neill 2011; Kryukov and Imanishi 2016; Florian P. Breitwieser et al. 2019) and therefore the removal of such sequences can also decrease the risk of false positive taxonomic assignment. To remove multiple hosts or other sequences, all reference genomes can be combined into a single FASTA reference file. Short read host removal can be carried out with Bowtie2 (Langmead and Salzberg 2012; Langmead et al. 2019) and minimap2 (Li 2018) for long reads, both in combination with SAMtools (Li et al. 2009; Danecek et al. 2021), where reads are aligned against the reference genome and the off-target (unaligned) reads are then converted back to FASTQ format for classification.\nFinally, nf-core/taxprofiler can optionally perform run merging where libraries have been sequenced over multiple lanes to generate one profile per sample or library. The final set of reads used for profiling can be optionally saved for downstream re-use. Throughout all steps, relevant statistics and log files are generated and used both for the final pipeline run report as well as saved into the results directory of the pipeline run for further inspection where necessary.\n\n\n11.1.3 Profiling\nThere are many types of metagenomic profiling techniques, from profiling against whole-genome references with alignment or k-mer based approaches, to methods involving alignment to species-specific marker-gene families (Quince et al. 2017; Ye et al. 2019). nf-core/taxprofiler aims to support and include all established classification or profiling tools as requested by the community.\nThe choice of tools used in a pipeline run is up to the user, with a tool being executed when both the corresponding database and --run_&lt;tool&gt; flag is provided. Specific classification settings for each tool and database are specified in the database CSV input sheet. Some tools also have pipeline level command-line flags for controlling certain aspects of output files.\nThe following classifiers and profilers are supported in version 1.1.0 of nf-core/taxprofiler: Kraken2 (Wood, Lu, and Langmead 2019), Bracken (Lu et al. 2017), KrakenUniq (F. P. Breitwieser, Baker, and Salzberg 2018), Centrifuge (Kim et al. 2016), MALT (Vågene et al. 2018), DIAMOND (Buchfink, Reuter, and Drost 2021), Kaiju (Menzel, Ng, and Krogh 2016), MetaPhlAn (Blanco-Míguez et al. 2023), mOTUs (Ruscheweyh et al. 2022), ganon (Piro et al. 2020), KMCP (Shen et al. 2023). Table 1 summarises the category and reference database type for each tool.\nBy default, nf-core/taxprofiler produces the per-sample main taxonomic classification profile from a tool or a tool’s report generation tool. The output is normally in the form of counts per reference sequencing, with additional statistics about the hits of a particular organism (estimated abundance, taxonomic level etc.). Users can also optionally request output of per-read classification output, and output such as classified and unclassified reads in FASTQ format, where supported.\nThe pipeline provides high efficiency, particularly during the metagenomic classification stage, through the inherent parallelisation provided by Nextflow. While metagenomic classification is comparatively computationally intensive (in terms of memory and execution time; due to a combination of sequencing depth and number of reference genomes), Nextflow automatically optimises the execution order of all the steps in pipeline, maximising the number parallel running of multiple profilers and/or databases at any given time point, as far as the available computational resources allow. For local machines such as laptops or desktops, Nextflow will automatically detect all available computational resources but this is customisable using Nextflow configuration files. For HPC and cloud infrastructure, users typically have to define the computational infrastructural environment the pipeline is being executed on (CPU or memory limitations, queues, instance types, etc.). To facilitate the pipeline set-up, nf-core/taxprofiler supports pre-defined centralised generic and pipeline-specific institutional Nextflow configurations as provided by nf-core/configs (https://nf-co.re/configs; more than 90 institutions at the time of writing). However, users are still welcome to supply their own custom configuration files, further refining computational limitations or execution specifications.\n\n\n11.1.4 Post-profiling\nIn metagenomic studies, it is common practise to compare the profiles among many samples, and the results of multiple profiles are normally stored in ‘taxon tables’, i.e, counts per reference taxon (rows), for each sample (columns). When available, nf-core/taxprofiler supports the option to produce the ‘native’ taxon table of each classification tool when multiple samples are run.\nOne of the challenges that researchers face when comparing multiple taxonomic classifiers or profilers is the heterogenous output formats that are produced, that often require custom parsing and merging scripts for each tool to standardise. To facilitate more user-friendly cross-comparisons between tools, nf-core/taxprofiler utilises the TAXPASTA tool (Beber et al. 2023) to generate standardised profiles and generate multi-sample tables.\nSummary statistics for the entire pipeline are visualised and displayed in a customisable MultiQC report (Ewels et al. 2020). When supported, quality control of data and pipeline runs are shown for manual verification. Krona plots (Ondov, Bergman, and Phillippy 2011) can also optionally be generated for supported tools to help provide further visualisation of taxonomic profiles.\n\n\n11.1.5 Output\nTo summarise, the main default output from nf-core/taxprofiler are both classifier ‘native’ and standardised single- and multi-sample taxonomic profiles with counts per-taxon and an interactive MultiQC run report with all run statistics, in addition to the raw log files themselves where available.\nThe MultiQC run report displays statistics and summary visualisations for all steps of the pipeline where possible, lists of versions for all tools of each step of the pipeline, and provides a dynamically-constructed text for the recommended ‘methods’ text for reporting how the pipeline was executed (including relevant citations) that users can use in their own publications.\nOptional outputs can include other types of profiles (e.g. per read classification) and in other formats as produced by the tools themselves, as well as raw reads from preprocessing steps and output visualisations from Krona. Nextflow resource usage and trace reports are also by default produced for users to check pipeline performance.\n\n\n\n11.2 Comparison with other solutions\nnf-core/taxprofiler has been specifically developed for the analysis of whole-genome, metagenomic sequencing data. While other types of taxonomic profiling data such as 16S amplicon sequencing are well established fields with a range of popular high-quality and best-practise tools pipelines (e.g. (Blanco-Míguez et al. 2023; Schloss et al. 2009)) and databases (DeSantis et al. 2006; Yilmaz et al. 2014), ‘gold standard’ tools and databases for metagenomics remain much less established. Thus, the need for highly-multiplexed classification is more desirable for the newer metagenomics methods.\nWe searched Google Scholar for open-source pipelines published or released in the last 5 years (at the time of writing, since 2018) that were designed primarily for metagenomic classification screening, that supported at least 2 classifiers, had at least one preprocessing step and were not specifically targeted at read classification of specific domains of taxa (e.g. viruses or bacteriophages only). We also included an additional pipeline at the recommendations of the authors of the pipeline due to the functional overlap to nf-core/taxprofiler. We then evaluated the pipelines based on their publications and documentation for typical metagenomic profiling workflow steps, and a range of criteria related to expectations of modern bioinformatic workflows that can be summarised in the following four criteria: reproducibility, accessibility, scalability, and portability (Wratten, Wilm, and Göke 2021). After searching, we selected the following pipelines for comparison with nf-core/taxprofiler: sunbeam (v4, Clarke et al. 2019), Unipro UGENE (v48, Rose et al. 2019), TAMA (githash: 3a22c8f, Sim et al. 2020), and StaG-mwc (0.7.0, Boulund et al. 2023). \nIn terms of accessibility, all pipelines have documentation describing the installation steps, usage instructions, and output files. However, there are varying levels of detail and comprehensiveness. In particular, StaG-mwc and nf-core/taxprofiler have the most detailed descriptions of all possible output files for every supported module, whereas Unipro UGENE and sunbeam have very minimal to possibly unfinished output documentation. For execution options, most of the pipelines provide CLI execution, except for Unipro UGENE which offers only GUI-based pipeline set-up (despite a command-line execution of the GUI generated configuration). In particular, nf-core/taxprofiler is the only pipeline providing both CLI and GUI interfaces for pipeline run execution.\nCriteria covering portability also overlap with accessibility, as it implies options for and ease of different users running on different types of computing infrastructure, whether that is on their own laptop, on an HPC cluster, or in the cloud. Unipro UGENE is the only pipeline that explicitly satates support for execution on all three major operating systems (Linux, OSX, Windows), whereas StaG-mwc and nf-core/taxprofiler can be run on unix operating systems (albiet possibly on Windows via Windows Subsystem for Linux (WSL)), and sunbeam and TAMA are only being supported on Linux.\nWhile all pipelines support ‘local’ machine execution (e.g. personal laptops or desktops), a large portion of academic users execute computationally intensive bioinformatic tasks on HPC clusters. In these contexts, pipeline task submissions are normally managed by job schedulers, thus integration with schedulers is an important criterion for running large multi-step and parallelised pipelines. The three pipelines leveraging workflow managers (Snakemake (Mölder et al. 2021) and Nextflow) support integration with schedulers (StaG-mwc, sunbeam, and nf-core/taxprofiler) with nf-core/taxprofiler supporting the most by far (&gt;10 scheduling systems) as natively offered by Nextflow. This allows the greatest possible choice for users in terms of which HPC infrastructure they can execute their pipeline on. As an extension of this, only nf-core/taxprofiler has explicit support for cloud computing (e.g. AWS, GCP, or Microsoft Azure), again maximising user choice and portability when it comes to running the pipeline.\nIn terms of scalability, the aforementioned integration with schedulers and cloud computing support implicitly maximises efficiency and parallellisation of pipeline runs, providing good scalability for varying numbers of input files and steps in the pipeline. Again, the three workflow manager based pipelines provide scalability, whereas there is no mention neither Unipro UGENE nor TAMA in reference to parallel task execution. Furthemore, all pipelines except TAMA, allowed per-process customisation of computational resources, something critical for maximising efficient scalability to ensure only the necessary resources for a given step of a pipeline are requested.\nIn terms of reproducibility, all five pipelines are good at ensuring reproducibility in terms of pipeline and software versioning (allowing re-execution of pipeline runs using the same software), with only tama not having stable versioned releases. However, installing software manually across different infrastructures can result in variability in the execution of each software 2 (Di Tommaso et al. 2017).The current most popular solution to the problem of inconsistent software environments is to use container engines such as Docker or Apptainer to run container images which are isolated, deterministic computing environments which can be executed by any system providing a container runtime. Only Unipro UGENE does not document the use of a container system, with nf-core/taxprofiler offering the biggest choice for users courtesy of Nextflow (6 different engine systems at the time of writing).\nFinally, we compared metagenomics related functionality between the pipelines. All pipelines support short-read FASTQ input, but only nf-core/taxprofiler explicitly reports long-read support, while the documentation in Unipro UGENE states that assembled contigs are possible input to some of the profilers. All pipelines support read preprocessing (adapter clipping, and merging). In terms of tools used for preprocessing, Trimmomatic (Bolger, Lohse, and Usadel 2014) is popular across the other pipelines but is not supported in nf-core/taxprofiler. Only sunbeam and nf-core/taxprofiler support complexity filtering to remove low sequence diversity reads. In fact within sunbeam, the authors developed their own dedicated, performant complexity filtering tool Komplexity (Clarke et al. 2019). Most pipelines support some form of host removal (only TAMA did not support this), and it is likely possible with Unipro UGENE (although not directly described). In all cases, host removal consists of mapping processed reads with an aligner and using the off-target reads for downstream profiling (as implemented in nf-core/taxprofiler), however StaG-mwc has an additional separate metagenomic host removal step with Kraken2. nf-core/taxprofiler supports by far the largest number of taxonomic classifers and profilers at 11 as of v1.1.0 - providing the greatest choice to users - with StaG-mwc offering 7, and the remaining pipelines only 3. Only nf-core/taxprofiler and partly StaG-mwc explicitly support running each profiler with multiple databases. nf-core/taxprofiler is the only pipeline that supports running an arbitrary number of different metagenomic profiler databases each with their own settings - making it useful for tool parameter comparison, testing different databases, or reducing the size of each database (e.g. per domain) to make it more flexibility for running on smaller computational infrastructure. StaG-mwc allows multiple references for their short-read alignment steps rather than the metagenomic profilers. For output, nf-core/taxprofiler, StaG-mwc, and sunbeam (via an extension) support a singular run report for summarising all preprocessing step. Only nf-core/taxprofiler and TAMA produce standardised output for all taxonomic profilers, the former with the dedicated standalone tool TAXPASTA (Beber et al. 2023). However Unipro UGENE additionally offers a ‘consensus’ profile using WEVOTE (Metwally et al. 2016).\nTo summarise, many of the pipelines reviewed here offer similar functionality, with particularly StaG-mwc having a strong overlap with nf-core/taxprofiler. Thus, users in most cases will be able to select the pipeline depending on which framework they feel most comfortable with. However the advantages of nf-core/taxprofiler mainly come from the offering of the greatest choice of tools, the benefits provided by Nextflow whereby it provides the greatest number of computational infrastructure types the pipeline can be executed on, and container systems can be used to ensure reproducibility, and the support of the nf-core community due to the centralised pool of ‘plug-and-play’ modules to make it easier to update the pipeline over time to add new tool.\nThe functionality offered by other pipelines not currently supported by nf-core/taxprofiler include sequencing saturation estimation (StaG-mwc), taxonomy-free composition comparison (StaG-mwc), functional profiling (StaG-mwc), de novo assembly (sunbeam), and reference mapping (StaG-mwc, sunbeam). We do not plan to support de novo assembly or functional profiling in nf-core/taxprofiler as we feel these are already better served by other existing dedicated pipelines within the nf-core ecosystem [nf-core/mag for _de novo assembly, Krakau et al. (2022), and nf-core/funcscan for functional profiling https://nf-co.re/funcscan], as well as elsewhere [e.g. MetaWrap Uritskiy, DiRuggiero, and Taylor (2018);].\n\nWe note there exists a range of other pipelines that also include some form of taxonomic classification. However often these pipelines have been developed with a different main purpose (e.g. Assembly and binning for nf-core/mag (Krakau et al. 2022), MetaWRAP (Uritskiy, DiRuggiero, and Taylor 2018), SqueezeMeta (Tamames and Puente-Sánchez 2018), or MEDUSA (Morais et al. 2022); Metagenomic read alignment with CCMetaGen (Marcelino et al. 2020) and Wochenende (Rosenboom et al. 2022))."
  },
  {
    "objectID": "taxprofiler-manuscript.html#footnotes",
    "href": "taxprofiler-manuscript.html#footnotes",
    "title": "nf-core/taxprofiler: highly parallelised and flexible pipeline for metagenomic taxonomic classification and profiling",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor an ‘infamous’ case of adapter sequences in a published eukaryotic genome, see the following blog posts\nGraham Etherington: https://web.archive.org/web/20201219022000/http://grahametherington.blogspot.com/2014/09/why-you-should-qc-your-reads-and-your.html?m=1why-you-should-qc-your-reads-and-your.html Sixing Huang: https://web.archive.org/web/20220904205331/https://dgg32.medium.com/carp-in-the-soil-1168818d2191\n(Accessed 2023-08-25)↩︎\nAs demonstrated in this blogpost from Paweł Przytuła: https://web.archive.org/web/20230320223436/https://appsilon.com/reproducible-research-when-your-results-cant-be-reproduced/ (Accessed 2023-08-25)↩︎"
  }
]